{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install investpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import wrds\n",
    "# import data_read\n",
    "import pull_WRDS_call_reports, pull_treasuries_data\n",
    "import pull_mbb_data\n",
    "import data_preprocessing, compute_treasury_changes\n",
    "# import calc_functions\n",
    "# import Calc_table_statistic\n",
    "import helper_functions\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idrssd_to_lei = pd.read_parquet('../manual data/idrssd_to_lei.parquet')\n",
    "# lei_legalevents = pd.read_parquet('../manual data/lei_legalevents.parquet')\n",
    "# lei_main = pd.read_parquet('../manual data/lei_main.parquet')\n",
    "# lei_successorentity = pd.read_parquet('../manual data/lei_successorentity.parquet')\n",
    "# wrds_bank_crsp_link = pd.read_parquet('../manual data/wrds_bank_crsp_link.parquet')\n",
    "# wrds_call_research = pd.read_parquet('../data/manual/wrds_call_research.parquet')\n",
    "wrds_call_research = pull_WRDS_call_reports.load_wrds_call_research()\n",
    "# wrds_struct_rel_ultimate = pd.read_parquet('../manual data/wrds_struct_rel_ultimate.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrds_bank_crsp_link['rssd9001'] = wrds_bank_crsp_link['rssd9001'].astype('int')\n",
    "wrds_call_research['rssd9001'] = wrds_call_research['rssd9001'].astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Table A1, you need:\n",
    "\t1.\tTotal Assets (assets)\n",
    "\t2.\tCash Holdings (cash)\n",
    "\t3.\tSecurities (Total, Treasury, RMBS, CMBS, ABS, Other) (securities, possibly other breakdowns)\n",
    "\t4.\tLoans (Total, Real Estate, Commercial, Consumer, etc.)\n",
    "\t5.\tReverse Repo and Fed Funds Sold (reverse_repo, fedfundsrate)\n",
    "\t6.\tCategorization into Bank Size Groups\n",
    "\t•\tSmall banks: Assets < $1.384B\n",
    "\t•\tLarge banks (non-GSIB): Assets ≥ $1.384B\n",
    "\t•\tGSIB: Systemically important banks (may require separate classification logic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Categorize Banks by Size: Use the assets column to classify banks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Compute Median & Standard Deviation for Each Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "# Step 1: Select data for Q1 2022 explicitly\n",
    "report_date = datetime.date(2022, 3, 31)\n",
    "df_date = wrds_call_research[wrds_call_research['date'] == pd.Timestamp(report_date)].copy()\n",
    "\n",
    "# Verify unique banks at reporting date\n",
    "num_banks = df_date['rssd9001'].nunique()\n",
    "print(f\"Number of banks as of {report_date}: {num_banks}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# small, large(non gsib), gsib\n",
    "# Categorize banks based on total asset size and GSIB status\n",
    "small_bank_threshold = 1_384_000  # Assets in thousands (1.384B)\n",
    "\n",
    "# First classify banks into Small vs Large\n",
    "df_date[\"bank_category\"] = np.where(\n",
    "    df_date[\"assets\"] < small_bank_threshold, \"Small\", \"Large (non-GSIB)\"\n",
    ")\n",
    "\n",
    "# Define GSIB banks explicitly by RSSD IDs\n",
    "gsib_list = [\n",
    "    852218, 480228, 476810, 413208, # JP Morgan, Bank of America, Citigroup, HSBC\n",
    "    2980209, 2182786, 541101, 655839, 1015560, 229913, # Barclays, Goldman Sachs, BNY Mellon, etc.\n",
    "    1456501, 722777, 35301, 925411, 497404, 3212149, # Morgan Stanley, Santander, State Street, etc.\n",
    "    451965 # Wells Fargo\n",
    "]\n",
    "\n",
    "# Within large banks, classify GSIB banks separately\n",
    "df_date.loc[\n",
    "    (df_date[\"bank_category\"] == \"Large (non-GSIB)\") & \n",
    "    (df_date[\"rssd9001\"].isin(gsib_list)), \n",
    "    \"bank_category\"\n",
    "] = \"GSIB\"\n",
    "\n",
    "# Verify categories\n",
    "print(df_date[\"bank_category\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explicitly calculation: other_security & other_re_loan & loanstonondep\n",
    "df_date['other_security'] = df_date['securities'].fillna(0) - (\n",
    "    df_date[['treasurysec', 'residentialmbsat', 'commercialmbsat', 'absassets']].fillna(0).sum(axis=1)\n",
    ")\n",
    "\n",
    "df_date['other_re_loan'] = df_date['reloans'].fillna(0) - (\n",
    "    df_date[['loans1to4fam', 'realoansnonres']].fillna(0).sum(axis=1)\n",
    ")\n",
    "\n",
    "# Loan to Non-Depository (loanstonondep)\n",
    "df_date['loanstonondep'] = df_date[['otherciloans', 'otherbankacceptances']].fillna(0).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define all asset-related columns clearly and explicitly\n",
    "asset_cols = {\n",
    "    'cash': 'Cash',\n",
    "    'securities': 'Security',\n",
    "    'treasurysec': 'Treasury',\n",
    "    'residentialmbsat': 'RMBS',\n",
    "    'commercialmbsat': 'CMBS',\n",
    "    'absassets': 'ABS',\n",
    "    'other_security': 'Other Security',\n",
    "    'loansnet': 'Total Loan',\n",
    "    'reloans': 'Real Estate Loan',\n",
    "    'loans1to4fam': 'Residential Mortgage',\n",
    "    'realoansnonres': 'Commercial Mortgage',\n",
    "    'other_re_loan': 'Other Real Estate Loan',\n",
    "    'agloans': 'Agricultural Loan',\n",
    "    'ciloans': 'Commercial & Industrial Loan',\n",
    "    'persloans': 'Consumer Loan',\n",
    "    'loanstonondep': 'Loan to Non-Depository',\n",
    "    'fedfundsrepoasset': 'Fed Funds Sold',\n",
    "    'fedfundsrepoliab': 'Reverse Repo' \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporarily fill any missing columns with zeros (for safety)\n",
    "for col in ['loans1to4fam', 'realoansnonres', 'loanstonondep', 'fedfundsrepoliab']:\n",
    "    if col not in df_date.columns:\n",
    "        df_date[col] = 0\n",
    "\n",
    "# Compute percentages of each asset category relative to total assets\n",
    "df_date['assets'] = df_date['assets'].replace({0: np.nan})\n",
    "\n",
    "for col in asset_cols.keys():\n",
    "    df_date[f'{col}_pct'] = (df_date[col].fillna(0) / df_date['assets']) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Aggregate separately (sum percentages explicitly)\n",
    "aggregate_assets_sum = df_date['assets'].sum()\n",
    "\n",
    "aggregate_pct_dict = {\n",
    "    f'{col}_pct': (df_date[col].sum() / aggregate_assets_sum) * 100\n",
    "    for col in asset_cols.keys()\n",
    "}\n",
    "\n",
    "aggregate_df = pd.DataFrame(aggregate_pct_dict, index=['Aggregate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute median and std for other bank categories\n",
    "grouped = df_date.groupby('bank_category')\n",
    "\n",
    "non_agg_summary = grouped[[f'{col}_pct' for col in asset_cols]].agg(['median', 'std'])\n",
    "\n",
    "# Add total assets (in billions) and number of banks explicitly\n",
    "non_agg_summary[('Total Asset ($B)', '')] = grouped['assets'].sum() / 1e6\n",
    "non_agg_summary[('Number of Banks', '')] = grouped['rssd9001'].nunique()\n",
    "\n",
    "# Flatten multi-level column index\n",
    "non_agg_summary.columns = [' '.join(col).strip() for col in non_agg_summary.columns.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_agg_summary2 = grouped[[f'{col}' for col in asset_cols]].agg(['sum'])\n",
    "non_agg_summary2.columns = [' '.join(col).strip() for col in non_agg_summary2.columns.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_agg_summary2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns clearly\n",
    "rename_dict = {}\n",
    "for key, val in asset_cols.items():\n",
    "    rename_dict[f'{key}_pct median'] = f'{val} Median'\n",
    "    rename_dict[f'{key}_pct std'] = f'{val} Std'\n",
    "\n",
    "non_agg_summary.rename(columns=rename_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explicit calculation of Aggregate row (sum percentages)\n",
    "aggregate_data = {f'{val} Median': (df_date[col].sum() / aggregate_assets_sum) * 100 for col, val in asset_cols.items()}\n",
    "aggregate_summary = pd.DataFrame(aggregate_pct_dict, index=['Aggregate'])\n",
    "\n",
    "# Add total asset sum and bank count explicitly for aggregate\n",
    "aggregate_extra = pd.DataFrame({\n",
    "    'Total Asset ($B)': aggregate_assets_sum / 1e6,  # convert thousands to billions\n",
    "    'Number of Banks': df_date['rssd9001'].nunique()\n",
    "}, index=['Aggregate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregate_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 10: Clearly define Total Asset and Number of Banks\n",
    "aggregate_assets_sum = df_date['assets'].sum()\n",
    "aggregate_extra = pd.DataFrame({\n",
    "    'Total Asset ($B)': [aggregate_assets_sum / 1e6],  # Convert from thousands to billions\n",
    "    'Number of Banks': df_date['rssd9001'].nunique()\n",
    "}, index=['Aggregate'])\n",
    "\n",
    "# Clearly define aggregate percentage DataFrame\n",
    "aggregate_pct_dict = {\n",
    "    f'{col}_pct': (df_date[col].sum() / aggregate_assets_sum) * 100\n",
    "    for col in asset_cols.keys()\n",
    "}\n",
    "aggregate_pct_df = pd.DataFrame(aggregate_pct_dict, index=['Aggregate'])\n",
    "\n",
    "# Create std rows as NaNs explicitly for aggregate (since it's sum, no std)\n",
    "aggregate_std_df = pd.DataFrame({f'{col}_pct': np.nan for col in asset_cols.keys()}, index=['Aggregate'])\n",
    "\n",
    "# Rename columns clearly (match non_agg_summary columns)\n",
    "aggregate_pct_df.columns = [f'{asset_cols[col.split(\"_pct\")[0]]} Median' for col in aggregate_pct_df.columns]\n",
    "\n",
    "# Combine median and NaN std explicitly\n",
    "aggregate_summary_final = pd.concat([aggregate_extra, aggregate_pct_df], axis=1)\n",
    "for col in aggregate_summary_final.columns:\n",
    "    if 'Median' in col:\n",
    "        aggregate_summary_final[col.replace('Median', 'Std')] = np.nan  # explicitly NaN for Aggregate std\n",
    "\n",
    "# Ensure columns order matches non-aggregate exactly\n",
    "aggregate_summary_final = aggregate_summary_final[non_agg_summary.columns]\n",
    "\n",
    "# Step 11: Combine aggregate and non-aggregate clearly\n",
    "final_summary = pd.concat([aggregate_summary_final, non_agg_summary])\n",
    "\n",
    "# Replace infinite values with NaN and round clearly\n",
    "final_summary.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "final_summary = final_summary.round(2)\n",
    "\n",
    "# After you obtain final_summary (before transposing):\n",
    "\n",
    "# Reorder columns clearly to put \"Total Asset\" and \"Number of Banks\" first\n",
    "first_cols = ['Total Asset ($B)', 'Number of Banks']\n",
    "other_cols = [col for col in final_summary.columns if col not in first_cols]\n",
    "\n",
    "final_summary = final_summary[first_cols + other_cols]\n",
    "\n",
    "# Now transpose explicitly\n",
    "final_summary['Number of Banks'] = final_summary['Number of Banks'].astype(int)\n",
    "final_table = final_summary.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_summary['Number of Banks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_table_styled = (\n",
    "    final_table.style\n",
    "    .format(precision=2, na_rep='')\n",
    "    .set_properties(**{\n",
    "        'text-align': 'center',\n",
    "        'font-size': '14px',\n",
    "        'padding': '8px'\n",
    "    })\n",
    "    .set_table_styles([\n",
    "        {'selector': 'th',\n",
    "         'props': [('background-color', 'white'),\n",
    "                   ('color', 'black'),\n",
    "                   ('text-align', 'center'),\n",
    "                   ('font-size', '15px'),\n",
    "                   ('border-bottom', '2px solid black'),\n",
    "                   ('padding', '10px')]},\n",
    "        {'selector': 'td',\n",
    "         'props': [('background-color', 'white'),\n",
    "                   ('color', 'black')]}\n",
    "    ])\n",
    ")\n",
    "\n",
    "# Display styled table explicitly\n",
    "display(final_table_styled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_table = final_table.rename(index=lambda x: x.replace(\"Commercial & Industrial\", \"C/I\"))\n",
    "final_table = final_table.rename(index=lambda x: x.replace(\"Total Asset ($B)\", \"Total Asset (Billions)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper_functions.save_dataframe_as_latex_table_1(final_table, filename=\"replicated_table_1A.tex\", caption=\"Replicated Table 1A: Bank Asset Composition\", label=\"tab:replicated1A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_to_image(df, filename=\"dataframe.png\"):\n",
    "    fig, ax = plt.subplots(figsize=(len(df.columns) * 1.2, len(df) * 0.5))  # Adjust size dynamically\n",
    "    ax.axis('tight')\n",
    "    ax.axis('off')\n",
    "    \n",
    "    table = pd.plotting.table(ax, df, loc='center', cellLoc='center', colWidths=[0.2]*len(df.columns))\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(10)\n",
    "    table.scale(1.2, 1.2)  # Adjust scale\n",
    "    \n",
    "    plt.savefig(filename, bbox_inches='tight', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# dataframe_to_image(final_table, \"table_a1.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_agg_summary2.rename(columns=lambda x: x.replace(\" sum\", \"\"), inplace=True)\n",
    "non_agg_summary2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregate_sums = non_agg_summary2.sum()\n",
    "total_assets_sum = aggregate_sums[[\"cash\", \"securities\", \"reloans\", \"ciloans\", \"other_security\"]]# .sum()\n",
    "total_liabilities_sum = aggregate_sums[[\"loansnet\", \"loanstonondep\", \"fedfundsrepoasset\", \"fedfundsrepoliab\"]]# .sum()\n",
    "\n",
    "# # Compute proportions\n",
    "# asset_aggregates = {\n",
    "#     category: (aggregate_sums[category] / total_assets_sum) * 100\n",
    "#     for category in [\"cash\", \"securities\", \"reloans\", \"ciloans\", \"other_security\"]\n",
    "# }\n",
    "\n",
    "# liability_aggregates = {\n",
    "#     category: (aggregate_sums[category] / total_liabilities_sum) * 100\n",
    "#     for category in [\"loansnet\", \"loanstonondep\", \"fedfundsrepoasset\", \"fedfundsrepoliab\"]\n",
    "# }\n",
    "\n",
    "# # Convert to DataFrame for display\n",
    "# aggregate_df = pd.DataFrame([asset_aggregates, liability_aggregates], index=[\"Assets (%)\", \"Liabilities (%)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_assets_sum, total_liabilities_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(helper_functions)\n",
    "helper_functions.save_stacked_bar_chart(total_assets_sum, total_liabilities_sum, \"assets_liabilities_chart.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
